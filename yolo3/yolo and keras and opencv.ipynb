{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog used is https://pysource.com/2019/06/27/yolo-object-detection-using-opencv-with-python/\n",
    "\n",
    "# all we need is opencv and numpy\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darknet : it’s the framework built from the developer of YOLO and made specifically for yolo.\n",
    "Advantage: it’s fast, it can work with GPU or CPU\n",
    "Disadvantage: it olny works with Linux os\n",
    "\n",
    "Darkflow: it’s the adaptation of darknet to Tensorflow (another deep learning framework).\n",
    "Advantage: it’s fast, it can work with GPU or CPU, and it’s also compatible with Linux, Windows and Mac.\n",
    "Disadvantage: the installation,it’s really complex, especially on windows\n",
    "\n",
    "Opencv: also opencv has a deep learning framework that works with YOLO. Just make sure you have opencv 3.4.2 at least.\n",
    "Advantage: it works without needing to install anything except opencv.\n",
    "Disadvantage: it only works with CPU, so you can’t get really high speed to process videos in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the algorythm. The run the algorythm we need three files:\n",
    "\n",
    "Weight file: it’s the trained model, the core of the algorithm to detect the objects.\n",
    "Cfg file: it’s the configuration file, where there are all the settings of the algorithm.\n",
    "Name files: contains the name of the objects that the algorithm can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yolo\n",
    "# get all these files from \n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image\n",
    "img = cv2.imread(\"bird.jpg\")\n",
    "img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have the image, but first we need it to convert it to blob. \n",
    "Blob is used to extract feature from the image and to resize them. \n",
    "YOLO accepts three sizes: 320x320, 416 x 416, 609 x 609\n",
    "the smaller the image the faster it is but also less accurate it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting objects\n",
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# outs is the image split up into its grid which is what yolo does with its accompanying vector\n",
    "# first 5 values are the vector each grid in an image gets from yolo are as follows:\n",
    "# object of any class present confidence, x,y(center of bounding box) , height, weight of bounding box.\n",
    "# after thats its the prediction of whether a specific object exists assigned to the class names from the coco.names file abovve\n",
    "# bird is the 14th name in the list\n",
    "# so the 18th element in the vector will refer to the probability of a bird existing in the picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the detection is done, and we only need to show the result on the screen.\n",
    "We then loop trough the outs array, we calculate the confidence and we choose a confidence threshold.\n",
    "\n",
    "The threshold goes from 0 to 1. The closer to 1 the greater is the accuracy of the detection, while the closer to 0 the less is the accuracy but also signifies a greater number of the objects detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing informations on the screen\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs: # loop through each grid vector\n",
    "    for detection in out: # isolate each vector\n",
    "        scores = detection[5:] # look at per class prediction\n",
    "        class_id = np.argmax(scores) # take highest prediction\n",
    "        confidence = scores[class_id] # if greater than our threshold, 0.5 in this case\n",
    "        if confidence > 0.5:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width) # center of bounding box predicted\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width) # h and w of predicted bounding box\n",
    "            h = int(detection[3] * height)\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h]) # add this proposed bounding box to the proposal list\n",
    "            confidences.append(float(confidence)) # add the confidence to a list as well\n",
    "            class_ids.append(class_id) # add the class_id found to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "# 0.5 is confidence threshold and 0.5 is IOU threshold.\n",
    "# returns indexes of actual boxes where objects are contained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the proposal with highest confidence score, remove it from B and add it to the final proposal list D. (Initially D is empty).\n",
    "\n",
    "Now compare this proposal with all the proposals — calculate the IOU (Intersection over Union) of this proposal with every other proposal. \n",
    "If the IOU is greater than the threshold N, remove that proposal from B.\n",
    "\n",
    "Again take the proposal with the highest confidence from the remaining proposals in B and remove it from B and add it to D.\n",
    "\n",
    "Once again calculate the IOU of this proposal with all the proposals in B and eliminate the boxes which have high IOU than threshold.\n",
    "\n",
    "This process is repeated until there are no more proposals left in B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally extract all the informations and show them on the screen.\n",
    "\n",
    "Box: contain the coordinates of the rectangle sorrounding the object detected.\n",
    "\n",
    "Label: it’s the name of the object detected\n",
    "\n",
    "Confidence: the confidence about the detection from 0 to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
